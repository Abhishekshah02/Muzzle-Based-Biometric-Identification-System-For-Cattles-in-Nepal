{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a028757b",
   "metadata": {},
   "source": [
    "The total number of images, minumum, maximum and average no. of images per cattle.  \n",
    "  \n",
    "For dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d0e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cattle: 455\n",
      "Total images: 2747\n",
      "Images per cattle: Min=1, Max=27, Avg=6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\1_base_256\"\n",
    "\n",
    "# Count cattle and images\n",
    "cattle_folders = os.listdir(dataset_path)\n",
    "image_counts = []\n",
    "\n",
    "for cattle_id in cattle_folders:\n",
    "    cattle_path = os.path.join(dataset_path, cattle_id)\n",
    "    if os.path.isdir(cattle_path):\n",
    "        images = [f for f in os.listdir(cattle_path) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        image_counts.append(len(images))\n",
    "\n",
    "print(f\"Total cattle: {len(cattle_folders)}\")\n",
    "print(f\"Total images: {sum(image_counts)}\")\n",
    "print(f\"Images per cattle: Min={min(image_counts)}, Max={max(image_counts)}, Avg={sum(image_counts)/len(image_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669e955",
   "metadata": {},
   "source": [
    "For dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aba289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cattle: 268\n",
      "Total images: 4923\n",
      "Images per cattle: Min=4, Max=70, Avg=18.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\Second dataset dataset\\2_base_256\"\n",
    "\n",
    "# Count cattle and images\n",
    "cattle_folders = os.listdir(dataset_path)\n",
    "image_counts = []\n",
    "\n",
    "for cattle_id in cattle_folders:\n",
    "    cattle_path = os.path.join(dataset_path, cattle_id)\n",
    "    if os.path.isdir(cattle_path):\n",
    "        images = [f for f in os.listdir(cattle_path) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        image_counts.append(len(images))\n",
    "\n",
    "print(f\"Total cattle: {len(cattle_folders)}\")\n",
    "print(f\"Total images: {sum(image_counts)}\")\n",
    "print(f\"Images per cattle: Min={min(image_counts)}, Max={max(image_counts)}, Avg={sum(image_counts)/len(image_counts):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f0753",
   "metadata": {},
   "source": [
    "Number of the class with less than 5 images.\n",
    "For dataset 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e242b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Number of classes with 1â€“5 images:\n",
      "1 image(s): 55 classes\n",
      "2 image(s): 39 classes\n",
      "3 image(s): 85 classes\n",
      "4 image(s): 33 classes\n",
      "5 image(s): 25 classes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your dataset (change this)\n",
    "dataset_path = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\1_base_256\"\n",
    "\n",
    "# Dictionary to store counts\n",
    "class_counts = {}\n",
    "\n",
    "# Loop over all class folders\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        num_images = len([f for f in os.listdir(class_folder) \n",
    "                          if os.path.isfile(os.path.join(class_folder, f))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Count how many classes fall into 1,2,3,4,5 images\n",
    "bucket_counts = Counter(class_counts.values())\n",
    "\n",
    "print(\"ðŸ“Œ Number of classes with 1â€“5 images:\")\n",
    "for i in range(1, 6):\n",
    "    print(f\"{i} image(s): {bucket_counts.get(i, 0)} classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e388d9c",
   "metadata": {},
   "source": [
    "For dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f18c81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Number of classes with 1â€“5 images:\n",
      "1 image(s): 0 classes\n",
      "2 image(s): 0 classes\n",
      "3 image(s): 0 classes\n",
      "4 image(s): 8 classes\n",
      "5 image(s): 4 classes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your dataset (change this)\n",
    "dataset_path = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\Second dataset dataset\\2_base_256\"\n",
    "\n",
    "# Dictionary to store counts\n",
    "class_counts = {}\n",
    "\n",
    "# Loop over all class folders\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        num_images = len([f for f in os.listdir(class_folder) \n",
    "                          if os.path.isfile(os.path.join(class_folder, f))])\n",
    "        class_counts[class_name] = num_images\n",
    "\n",
    "# Count how many classes fall into 1,2,3,4,5 images\n",
    "bucket_counts = Counter(class_counts.values())\n",
    "\n",
    "print(\"ðŸ“Œ Number of classes with 1â€“5 images:\")\n",
    "for i in range(1, 6):\n",
    "    print(f\"{i} image(s): {bucket_counts.get(i, 0)} classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d944896d",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------\n",
    "## For dataset 1\n",
    "Since i have the dataset already in the grayscale so for the preprocessing the only thing i have to do is augumentation for the class.  \n",
    "As the test and validate folder should have the original image of the images not the augumentation.So, according to the dataset it is divided into the train,test and validate in the following way:  \n",
    "\n",
    "-  Decide test, val, train_real counts per class:\n",
    "\n",
    "    - If n >= 10:  \n",
    "        test = max(1, round(0.15 * n))  \n",
    "        val = max(1, round(0.15 * n))  \n",
    "        train_real = n - test - val  \n",
    "\n",
    "    - If 4 <= n < 10:\n",
    "        test = 1, val = 1, train_real = n - 2\n",
    "\n",
    "    - If n == 3:\n",
    "        test = 1, val = 1, train_real = 1\n",
    "\n",
    "    - If n == 2:\n",
    "        test = 1, val = 0, train_real = 1 (we will create 1 augmented image for val later)\n",
    "\n",
    "    - If n == 1:\n",
    "        test = 1, val = 0, train_real = 0 (train images will be created by offline augmentation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split done. Summary saved to: C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\split_summary.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script A â€” split originals into train/val/test per-class using robust rules.\n",
    "\n",
    "Usage: edit DATA_ROOT and OUT_ROOT and run.\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# -------- USER SETTINGS --------\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\1_base_256\")    # folder with class subfolders\n",
    "OUT_ROOT  = Path(r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_1\")  # will contain train/val/test subfolders\n",
    "TARGET_TRAIN = 10   # target training images per class after offline augmentation\n",
    "MIN_VAL_AUG = True  # if val missing, use small augmented image later (flagging)\n",
    "# -------------------------------\n",
    "\n",
    "def decide_counts(n):\n",
    "    if n >= 10:\n",
    "        test = max(1, round(0.15 * n))\n",
    "        val  = max(1, round(0.15 * n))\n",
    "        train = n - test - val\n",
    "    elif 4 <= n < 10:\n",
    "        test = 1; val = 1; train = n - 2\n",
    "    elif n == 3:\n",
    "        test = 1; val = 1; train = 1\n",
    "    elif n == 2:\n",
    "        test = 1; val = 0; train = 1\n",
    "    elif n == 1:\n",
    "        test = 1; val = 0; train = 0\n",
    "    else:\n",
    "        test=0; val=0; train=0\n",
    "    return int(max(test,0)), int(max(val,0)), int(max(train,0))\n",
    "\n",
    "def ensure_dirs(p):\n",
    "    (p / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (p / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (p / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def main():\n",
    "    ensure_dirs(OUT_ROOT)\n",
    "    rows = []\n",
    "    for cls_dir in sorted(DATA_ROOT.iterdir()):\n",
    "        if not cls_dir.is_dir(): continue\n",
    "        imgs = sorted([p for p in cls_dir.iterdir() if p.suffix.lower() in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")])\n",
    "        n = len(imgs)\n",
    "        test_c, val_c, train_c = decide_counts(n)\n",
    "        # shuffle then select\n",
    "        random.shuffle(imgs)\n",
    "        test_imgs = imgs[:test_c]\n",
    "        val_imgs = imgs[test_c:test_c+val_c]\n",
    "        train_imgs = imgs[test_c+val_c:test_c+val_c+train_c]\n",
    "        # fallback: if val_c==0 but MIN_VAL_AUG True, we will mark val as augmented later\n",
    "        # Copy files\n",
    "        for p in train_imgs:\n",
    "            out = OUT_ROOT / \"train\" / cls_dir.name\n",
    "            out.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(p, out / p.name)\n",
    "        for p in val_imgs:\n",
    "            out = OUT_ROOT / \"val\" / cls_dir.name\n",
    "            out.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(p, out / p.name)\n",
    "        for p in test_imgs:\n",
    "            out = OUT_ROOT / \"test\" / cls_dir.name\n",
    "            out.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(p, out / p.name)\n",
    "\n",
    "        to_generate = max(0, TARGET_TRAIN - max(0, train_c))\n",
    "        rows.append({\n",
    "            \"class\": cls_dir.name,\n",
    "            \"n_original\": n,\n",
    "            \"train_real\": len(train_imgs),\n",
    "            \"val_real\": len(val_imgs),\n",
    "            \"test_real\": len(test_imgs),\n",
    "            \"to_generate_train\": to_generate,\n",
    "            \"val_is_augmented_needed\": (len(val_imgs)==0 and MIN_VAL_AUG)\n",
    "        })\n",
    "\n",
    "    # Save CSV summary\n",
    "    csv_path = OUT_ROOT / \"split_summary.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()) if rows else [])\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    print(\"Split done. Summary saved to:\", csv_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b9061",
   "metadata": {},
   "source": [
    "After splitting, it compute the no. of images needed in the train folder to be 10 and then generate the images by the augumenatition technique. Check the split_summary.csv if it is true for any class then it apply the mild augumentation to generate the validation image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e165aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amrit Shah\\AppData\\Local\\Temp\\ipykernel_15292\\3649991722.py:30: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
      "C:\\Users\\Amrit Shah\\AppData\\Local\\Temp\\ipykernel_15292\\3649991722.py:33: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.25),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script B â€” offline augment to reach target_train per class.\n",
    "\n",
    "Usage: edit PROCESSED_ROOT and adjust parameters.\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import csv\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# -------- USER SETTINGS --------\n",
    "PROCESSED_ROOT = Path(r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_1\")  # output of Script A\n",
    "SUMMARY_CSV = PROCESSED_ROOT / \"split_summary.csv\"\n",
    "TARGET_TRAIN = 10\n",
    "AUG_SAVE_QUALITY = 95\n",
    "# -------------------------------\n",
    "\n",
    "# augmentation pipeline for offline generation (diverse)\n",
    "aug_pipeline = A.Compose([\n",
    "    A.RandomResizedCrop(size=(224, 224), scale=(0.8,1.0), ratio=(0.9,1.1)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.08, rotate_limit=12, p=0.6),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
    "    A.OneOf([A.MotionBlur(blur_limit=3), A.MedianBlur(blur_limit=3), A.GaussianBlur(blur_limit=3)], p=0.2),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.25),\n",
    "])\n",
    "\n",
    "# mild augmentation for validation (if needed) -> minimal transformation\n",
    "val_aug = A.Compose([\n",
    "    A.RandomResizedCrop(size=(224, 224), scale=(0.95,1.0), ratio=(0.98,1.02)),\n",
    "    A.HorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "def read_summary():\n",
    "    rows = []\n",
    "    with open(SUMMARY_CSV, newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def list_train_real(cls):\n",
    "    p = PROCESSED_ROOT / \"train\" / cls\n",
    "    if not p.exists(): return []\n",
    "    return sorted([x for x in p.iterdir() if x.suffix.lower() in (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\")])\n",
    "\n",
    "def create_augmented_image(img_path, pipeline):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    out = pipeline(image=img)\n",
    "    aug = out['image']\n",
    "    aug_bgr = cv2.cvtColor(aug, cv2.COLOR_RGB2BGR)\n",
    "    return aug_bgr\n",
    "\n",
    "def save_aug(img_bgr, out_path):\n",
    "    cv2.imwrite(str(out_path), img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), AUG_SAVE_QUALITY])\n",
    "\n",
    "def main():\n",
    "    rows = read_summary()\n",
    "    for r in rows:\n",
    "        cls = r[\"class\"]\n",
    "        to_gen = int(r[\"to_generate_train\"])\n",
    "        val_aug_needed = r.get(\"val_is_augmented_needed\",\"False\").lower() in (\"true\",\"1\",\"yes\")\n",
    "        train_dir = PROCESSED_ROOT / \"train\" / cls\n",
    "        train_dir.mkdir(parents=True, exist_ok=True)\n",
    "        existing = list_train_real(cls)\n",
    "        existing_count = len(existing)\n",
    "        # If no real training images exist, use test/val images as source for augmentation generation (do not move them)\n",
    "        source_pool = existing.copy()\n",
    "        if len(source_pool) == 0:\n",
    "            # try using val or test if present (but DO NOT move them, use only as augmentation source)\n",
    "            for alt in (\"val\", \"test\"):\n",
    "                altdir = PROCESSED_ROOT / alt / cls\n",
    "                if altdir.exists():\n",
    "                    source_pool += sorted([x for x in altdir.iterdir() if x.suffix.lower() in (\".jpg\",\".jpeg\",\".png\")])\n",
    "            if len(source_pool) == 0:\n",
    "                print(f\"[WARN] No source images found for class {cls}; skipping augmentation.\")\n",
    "                continue\n",
    "\n",
    "        # Generate images\n",
    "        i = 0\n",
    "        while to_gen > 0:\n",
    "            src = random.choice(source_pool)\n",
    "            aug_img = create_augmented_image(src, aug_pipeline)\n",
    "            if aug_img is None:\n",
    "                print(f\"[WARN] failed to read {src}\")\n",
    "                break\n",
    "            out_name = f\"aug_train_{i:04d}__{src.stem}.jpg\"\n",
    "            save_aug(aug_img, train_dir / out_name)\n",
    "            i += 1\n",
    "            to_gen -= 1\n",
    "\n",
    "        # If val augmentation needed (mild), create a single augmented val image and save to val folder\n",
    "        if val_aug_needed:\n",
    "            val_dir = PROCESSED_ROOT / \"val\" / cls\n",
    "            val_dir.mkdir(parents=True, exist_ok=True)\n",
    "            # pick a source from test (prefer) or train\n",
    "            srcs = sorted([x for x in (PROCESSED_ROOT / \"test\" / cls).glob(\"*\")]) or sorted([x for x in (PROCESSED_ROOT / \"train\" / cls).glob(\"*\")])\n",
    "            if srcs:\n",
    "                src = random.choice(srcs)\n",
    "                aug_img = create_augmented_image(src, val_aug)\n",
    "                if aug_img is not None:\n",
    "                    save_aug(aug_img, val_dir / f\"aug_val__{src.stem}.jpg\")\n",
    "            else:\n",
    "                print(f\"[WARN] no source to create val augmentation for {cls}\")\n",
    "\n",
    "    print(\"Offline augmentation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5039d94",
   "metadata": {},
   "source": [
    "## For dataset 2\n",
    "As the dataset has minimum 4 images per class so here i have splitted the dataset in the following way:  \n",
    "\n",
    "For classes with â‰¥7 images: split 70/15/15 normally (round counts).  \n",
    "\n",
    "For classes with 4â€“7 images:  \n",
    "    - At least 1 image in the validate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7014e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Smart split done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "SOURCE_DIR = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\Second dataset dataset\\2_base_256\"\n",
    "TARGET_DIR = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_2\"\n",
    "MIN_TRAIN_IMAGES = 10   # minimum images per class in train after augmentation\n",
    "\n",
    "# -------------------------\n",
    "# STEP 1: SPLIT DATASET SMARTLY\n",
    "# -------------------------\n",
    "def smart_split(source_dir, target_dir):\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        os.makedirs(os.path.join(target_dir, split), exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "        if len(images) == 0:\n",
    "            continue\n",
    "\n",
    "        random.shuffle(images)\n",
    "        n = len(images)\n",
    "\n",
    "        # Small classes\n",
    "        if n < 4:\n",
    "            train_imgs = images\n",
    "            val_imgs = []\n",
    "            test_imgs = []\n",
    "        elif 4 <= n < 7:\n",
    "            train_count = max(2, n - 2)\n",
    "            val_count = 1\n",
    "            test_count = n - train_count - val_count\n",
    "            train_imgs = images[:train_count]\n",
    "            val_imgs = images[train_count:train_count + val_count]\n",
    "            test_imgs = images[train_count + val_count:]\n",
    "        else:  # n >= 10\n",
    "            train_count = int(n * 0.7)\n",
    "            val_count = int(n * 0.15)\n",
    "            test_count = n - train_count - val_count\n",
    "            train_imgs = images[:train_count]\n",
    "            val_imgs = images[train_count:train_count + val_count]\n",
    "            test_imgs = images[train_count + val_count:]\n",
    "\n",
    "        # Copy images\n",
    "        for split_name, split_imgs in zip([\"train\", \"val\", \"test\"], [train_imgs, val_imgs, test_imgs]):\n",
    "            split_class_dir = os.path.join(target_dir, split_name, class_name)\n",
    "            os.makedirs(split_class_dir, exist_ok=True)\n",
    "            for img in split_imgs:\n",
    "                shutil.copy(os.path.join(class_path, img), os.path.join(split_class_dir, img))\n",
    "\n",
    "    print(\"âœ… Smart split done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    smart_split(SOURCE_DIR, TARGET_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca633f8",
   "metadata": {},
   "source": [
    "After splitting, it compute the no. of images required in the train folder to be 10 and then generate the remaining images by the augumenatition technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e944f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting cattle_0100: 5 â†’ 10 images\n",
      "Augmenting cattle_0200: 7 â†’ 10 images\n",
      "Augmenting cattle_0400: 4 â†’ 10 images\n",
      "Augmenting cattle_0500: 9 â†’ 10 images\n",
      "Augmenting cattle_0900: 8 â†’ 10 images\n",
      "Augmenting cattle_1000: 8 â†’ 10 images\n",
      "Augmenting cattle_1100: 7 â†’ 10 images\n",
      "Augmenting cattle_1200: 7 â†’ 10 images\n",
      "Augmenting cattle_1300: 8 â†’ 10 images\n",
      "Augmenting cattle_1400: 9 â†’ 10 images\n",
      "Augmenting cattle_1500: 4 â†’ 10 images\n",
      "Augmenting cattle_1600: 9 â†’ 10 images\n",
      "Augmenting cattle_1700: 8 â†’ 10 images\n",
      "Augmenting cattle_1900: 5 â†’ 10 images\n",
      "Augmenting cattle_2000: 9 â†’ 10 images\n",
      "Augmenting cattle_2100: 2 â†’ 10 images\n",
      "Augmenting cattle_2200: 4 â†’ 10 images\n",
      "Augmenting cattle_2220: 4 â†’ 10 images\n",
      "Augmenting cattle_2320: 9 â†’ 10 images\n",
      "Augmenting cattle_2510: 7 â†’ 10 images\n",
      "Augmenting cattle_2740: 5 â†’ 10 images\n",
      "Augmenting cattle_2930: 4 â†’ 10 images\n",
      "Augmenting cattle_3100: 9 â†’ 10 images\n",
      "Augmenting cattle_3300: 9 â†’ 10 images\n",
      "Augmenting cattle_3400: 4 â†’ 10 images\n",
      "Augmenting cattle_3420: 2 â†’ 10 images\n",
      "Augmenting cattle_3802: 5 â†’ 10 images\n",
      "Augmenting cattle_3812: 8 â†’ 10 images\n",
      "Augmenting cattle_3814: 9 â†’ 10 images\n",
      "Augmenting cattle_3842: 9 â†’ 10 images\n",
      "Augmenting cattle_4259: 4 â†’ 10 images\n",
      "Augmenting cattle_4326: 7 â†’ 10 images\n",
      "Augmenting cattle_4399: 4 â†’ 10 images\n",
      "Augmenting cattle_4451: 4 â†’ 10 images\n",
      "Augmenting cattle_4488: 7 â†’ 10 images\n",
      "Augmenting cattle_4537: 8 â†’ 10 images\n",
      "Augmenting cattle_4549: 2 â†’ 10 images\n",
      "Augmenting cattle_4685: 7 â†’ 10 images\n",
      "Augmenting cattle_4717: 3 â†’ 10 images\n",
      "Augmenting cattle_4770: 7 â†’ 10 images\n",
      "Augmenting cattle_4921: 9 â†’ 10 images\n",
      "Augmenting cattle_4969: 8 â†’ 10 images\n",
      "Augmenting cattle_4971: 7 â†’ 10 images\n",
      "Augmenting cattle_4985: 7 â†’ 10 images\n",
      "Augmenting cattle_4995: 4 â†’ 10 images\n",
      "Augmenting cattle_5066: 9 â†’ 10 images\n",
      "Augmenting cattle_5073: 9 â†’ 10 images\n",
      "Augmenting cattle_5100: 5 â†’ 10 images\n",
      "Augmenting cattle_5112: 9 â†’ 10 images\n",
      "Augmenting cattle_5133: 8 â†’ 10 images\n",
      "Augmenting cattle_5138: 7 â†’ 10 images\n",
      "Augmenting cattle_5143: 6 â†’ 10 images\n",
      "Augmenting cattle_5153: 3 â†’ 10 images\n",
      "Augmenting cattle_5165: 7 â†’ 10 images\n",
      "Augmenting cattle_5197: 9 â†’ 10 images\n",
      "Augmenting cattle_5208: 2 â†’ 10 images\n",
      "Augmenting cattle_5234: 5 â†’ 10 images\n",
      "Augmenting cattle_5275: 9 â†’ 10 images\n",
      "Augmenting cattle_5282: 4 â†’ 10 images\n",
      "Augmenting cattle_5283: 9 â†’ 10 images\n",
      "Augmenting cattle_5307: 7 â†’ 10 images\n",
      "Augmenting cattle_5314: 9 â†’ 10 images\n",
      "Augmenting cattle_5355: 2 â†’ 10 images\n",
      "Augmenting cattle_5359: 7 â†’ 10 images\n",
      "Augmenting cattle_5427: 9 â†’ 10 images\n",
      "Augmenting cattle_5477: 6 â†’ 10 images\n",
      "Augmenting cattle_5556: 5 â†’ 10 images\n",
      "Augmenting cattle_5604: 9 â†’ 10 images\n",
      "Augmenting cattle_5605: 9 â†’ 10 images\n",
      "Augmenting cattle_5620: 8 â†’ 10 images\n",
      "Augmenting cattle_5630: 2 â†’ 10 images\n",
      "Augmenting cattle_5633: 9 â†’ 10 images\n",
      "Augmenting cattle_5634: 9 â†’ 10 images\n",
      "Augmenting cattle_5639: 8 â†’ 10 images\n",
      "Augmenting cattle_5658: 8 â†’ 10 images\n",
      "Augmenting cattle_5677: 8 â†’ 10 images\n",
      "Augmenting cattle_5761: 7 â†’ 10 images\n",
      "Augmenting cattle_5762: 4 â†’ 10 images\n",
      "Augmenting cattle_5777: 8 â†’ 10 images\n",
      "Augmenting cattle_5806: 9 â†’ 10 images\n",
      "Augmenting cattle_5815: 9 â†’ 10 images\n",
      "Augmenting cattle_5816: 6 â†’ 10 images\n",
      "Augmenting cattle_5925: 2 â†’ 10 images\n",
      "Augmenting cattle_5986: 3 â†’ 10 images\n",
      "Augmenting cattle_6017: 8 â†’ 10 images\n",
      "Augmenting cattle_6022: 5 â†’ 10 images\n",
      "Augmenting cattle_6124: 7 â†’ 10 images\n",
      "Augmenting cattle_6171: 8 â†’ 10 images\n",
      "Augmenting cattle_6189: 8 â†’ 10 images\n",
      "Augmenting cattle_6197: 8 â†’ 10 images\n",
      "Augmenting cattle_6199: 9 â†’ 10 images\n",
      "Augmenting cattle_6210: 7 â†’ 10 images\n",
      "Augmenting cattle_6213: 8 â†’ 10 images\n",
      "Augmenting cattle_6220: 8 â†’ 10 images\n",
      "Augmenting cattle_6237: 4 â†’ 10 images\n",
      "Augmenting cattle_6253: 5 â†’ 10 images\n",
      "Augmenting cattle_6266: 7 â†’ 10 images\n",
      "Augmenting cattle_6277: 8 â†’ 10 images\n",
      "Augmenting cattle_6278: 9 â†’ 10 images\n",
      "Augmenting cattle_6282: 8 â†’ 10 images\n",
      "Augmenting cattle_6283: 3 â†’ 10 images\n",
      "Augmenting cattle_6287: 9 â†’ 10 images\n",
      "Augmenting cattle_6294: 7 â†’ 10 images\n",
      "Augmenting cattle_6295: 7 â†’ 10 images\n",
      "Augmenting cattle_6442: 9 â†’ 10 images\n",
      "Augmenting cattle_6446: 5 â†’ 10 images\n",
      "Augmenting cattle_6458: 7 â†’ 10 images\n",
      "Augmenting cattle_6499: 6 â†’ 10 images\n",
      "Augmenting cattle_6505: 9 â†’ 10 images\n",
      "Augmenting cattle_6530: 7 â†’ 10 images\n",
      "Augmenting cattle_6606: 8 â†’ 10 images\n",
      "Augmenting cattle_8050: 2 â†’ 10 images\n",
      "Augmenting cattle_8094: 7 â†’ 10 images\n",
      "Augmenting cattle_8095: 5 â†’ 10 images\n",
      "Augmenting cattle_9021: 7 â†’ 10 images\n",
      "Augmenting cattle_9635: 5 â†’ 10 images\n",
      "Augmenting cattle_9773: 7 â†’ 10 images\n",
      "Augmenting cattle_9801: 7 â†’ 10 images\n",
      "âœ… Augmentation done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "TARGET_DIR = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_2\"\n",
    "MIN_TRAIN_IMAGES = 10 \n",
    "\n",
    "#Augmentation settings\n",
    "datagen = ImageDataGenerator( \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest' )\n",
    "\n",
    "def augment_train(target_dir, min_train_images=MIN_TRAIN_IMAGES):\n",
    "    train_dir = os.path.join(target_dir, \"train\")\n",
    "    for class_name in os.listdir(train_dir):\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "        n = len(images)\n",
    "\n",
    "        if n >= min_train_images:\n",
    "            continue\n",
    "\n",
    "        needed = min_train_images - n\n",
    "        print(f\"Augmenting {class_name}: {n} â†’ {min_train_images} images\")\n",
    "\n",
    "        i = 0\n",
    "        while needed > 0:\n",
    "            img_path = os.path.join(class_path, images[i % n])\n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            # generate 1 augmented image\n",
    "            for batch in datagen.flow(x, batch_size=1, save_to_dir=class_path,\n",
    "                                      save_prefix='aug', save_format='png'):\n",
    "                needed -= 1\n",
    "                i += 1\n",
    "                break  # only generate one per loop\n",
    "\n",
    "    print(\"âœ… Augmentation done!\")\n",
    "\n",
    "# -------------------------\n",
    "# MAIN\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    augment_train(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b77933",
   "metadata": {},
   "source": [
    "Detail of the dataset 2 in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31fa4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV generated at C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_2\\dataset_split.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "TARGET_DIR = r\"C:\\Users\\Amrit Shah\\Desktop\\Muzzle based Identification\\DL\\preprocess_dataset_2\"\n",
    "CSV_PATH   = os.path.join(TARGET_DIR, \"dataset_split.csv\")\n",
    "\n",
    "def generate_csv_from_split(target_dir, csv_path):\n",
    "    rows = [(\"split\", \"class\", \"filename\")]  # header row\n",
    "    \n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_dir = os.path.join(target_dir, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "\n",
    "        for class_name in os.listdir(split_dir):\n",
    "            class_path = os.path.join(split_dir, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            for img in os.listdir(class_path):\n",
    "                if img.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    rows.append((split, class_name, img))\n",
    "\n",
    "    # save CSV\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"âœ… CSV generated at {csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_csv_from_split(TARGET_DIR, CSV_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
